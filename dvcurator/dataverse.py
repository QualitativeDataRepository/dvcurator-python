#!/usr/bin/env python
# -*- coding: utf-8 -*-
#

def get_metadata(doi, token=None, host=None):
	"""
	Scrape all available metadata for a project from Dataverse

	:param doi: The persistent ID of the project (doi:xxxx/xxxxxx)
	:type doi: String
	:param token: Dataverse token, necessary if the project is unpublished
	:type token: String, or None
	:param host: Hostname of the dataverse instance (i.e. data.qdr.syr.edu), or None for the default
	:type host: String
	:return: Metadata block from Dataverse API, or None if error
	:rtype: list[str]
	"""
	import re, requests, dvcurator.hosts

	doi = doi.strip()
	if not doi.startswith("doi:"):
		print("Error: DOIs should start with \"doi:\"")
		return None
	
	# check for invalid DOI
	doi_suffix = doi[4:]  # Remove the "doi:" prefix
	doi_pattern = r"^10\.\d{4,9}/[-._;()/:A-Z0-9]+$"
	if not re.match(doi_pattern, doi_suffix, re.IGNORECASE):
		print(f"Error: Invalid DOI format: {doi}")
		return None

	
	# Scrape data and metadata from dataverse
	host = dvcurator.hosts.qdr_dataverse if not host else host 
	dataset_url = host + '/api/datasets/:persistentId/?persistentId=' + doi
	if (not token):
		dataset = requests.get(dataset_url)
	else:
		key = {'X-Dataverse-Key': token.strip()}
		dataset = requests.get(dataset_url, headers=key)
	
	try: 
		dataset = dataset.json()
	except:
		print("Error: " + host + " not serving JSON")
		return None

	if (dataset['status']=="ERROR"):
		print("Error: " + dataset['message'])
		return None
	
	return(dataset)

def get_citation(metadata):
	"""
	Extract and format the citation metadata block from the main metadata object

	:param metadata: Metadata block from `get_metadata()`
	:type metadata: list[str]
	:return: Index of metadata name:value combos
	:rtype: dict
	"""
	#metadata = get_metadata(doi, token, host)
	citation=metadata['data']['latestVersion']['metadataBlocks']['citation']['fields']
	fields = [] # Make an index of all the metadata fields
	values = []
	for entry in citation:
		fields.append(entry['typeName'])
		values.append(entry['value'])
	return dict(zip(fields, values)) 

# This pulls the "recommended citation" field
def get_biblio_citation(doi, token=None, host=None):
	"""
	Get the recommended citation from Dataverse

	:param doi: The persistent ID of the project (doi:xxxx/xxxxxx)
	:type doi: String
	:param token: Dataverse token, necessary if the project is unpublished
	:type token: String, or None
	:param host: Hostname of the dataverse instance (i.e. data.qdr.syr.edu), or None for the default
	:type host: String
	:return: Recommended citation, as generated by dataverse
	:rtype: String
	"""
	import requests, dvcurator.hosts
	host = dvcurator.hosts.qdr_dataverse if not host else host 

	search_api = host + "/api/search?q=dsPersistentId=%22" + doi + "%22"
	if (not token):
		query = requests.get(search_api)
	else:
		key = {'X-Dataverse-Key': token.strip()}
		query = requests.get(search_api, headers=key)

	query.raise_for_status()
	
	return query.json()['data']['items'][0]['citation']
	
# Actually download and extract the dataset
# This is the function run by the download and extract button
def download_dataset(metadata, folder, token=None, host=None):
	"""
	Download and extract dataset from Dataverse

	:param metadata: Metadata block from ```get_metadata()```
	:type metadata: list[str]
	:param token: Dataverse token, necessary if the project is unpublished
	:type token: String, or None
	:param host: Hostname of the dataverse instance (i.e. data.qdr.syr.edu), or None for the default
	:type host: String
	"""
	import zipfile, os, urllib, json, requests, dvcurator.hosts

	edit_path = os.path.normpath(os.path.join(folder, "QDR Prepared/1_extract"))
	if not os.path.isdir(edit_path):
		os.makedirs(edit_path) # Creates parents as well
		#print("Directory '%s' created" %folder_path)
	else: # If the folder already exists, don't overwrite!!
		print("Error: extract folder already exists!")
		return None

	# Write metadata
	with open(os.path.join(folder, "Original metadata.json"), "w") as outfile:
		json.dump(metadata['data']['latestVersion']['files'], outfile, indent=4)

	# Write the zip file
	doi = metadata['data']['latestVersion']['datasetPersistentId']
	zip_url = dvcurator.hosts.qdr_dataverse if not host else host 
	zip_url += '/api/access/dataset/:persistentId/?persistentId=' + doi
	zip_url += '&format=original'
	print("Downloading Dataverse files", end="... ")
	zip_path = os.path.join(folder, "Original Deposit.zip")
	opener = urllib.request.build_opener()
	if token:
		opener.addheaders = [('X-Dataverse-Key', token.strip())]
	urllib.request.install_opener(opener)
	urllib.request.urlretrieve(zip_url, zip_path)
	print("Done!")
				
	print("Extracting Dataverse files", end="... ")
	with zipfile.ZipFile(zip_path, 'r') as zip_ref:
		zip_ref.extractall(edit_path)
	print("Done!")

	manifest = os.path.join(edit_path, 'MANIFEST.TXT')
	if (os.path.exists(manifest)):
		os.remove(manifest)
		
	return edit_path
